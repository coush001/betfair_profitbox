{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e1a659-9ae2-46e3-a829-17379e51be6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hugocoussens/git/betfair_profitbox/research\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0087c1b-0645-4e34-b717-cf492567d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, csv\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "paths = [str(p) for p in Path(\"./hist_data/ADVANCED/\").rglob(\"*\") if p.is_file()]\n",
    "paths = [p for p in paths if not p.lower().endswith(\".ds_store\")]\n",
    "matches = []\n",
    "\n",
    "for path in paths:\n",
    "    with open(path, \"r\") as f:\n",
    "        try:\n",
    "            for line in f:\n",
    "                if '\"marketType\":\"MATCH_ODDS\"' in line and '\"status\":\"ACTIVE\"' and '\"name\":\"Match Odds\"' in line:\n",
    "                    matches.append(line.strip())\n",
    "        except: print(path)\n",
    "\n",
    "\n",
    "lines = matches  # your list of JSON strings\n",
    "\n",
    "def safe_load_json(s):\n",
    "    try: return json.loads(s)\n",
    "    except: return json.loads(s[s.index(\"{\"):])\n",
    "\n",
    "unique = {}\n",
    "for ln in lines:\n",
    "    o = safe_load_json(ln)\n",
    "    for mc in o.get(\"mc\", []):\n",
    "        md = mc.get(\"marketDefinition\", {})\n",
    "        k = (md.get(\"eventId\"), mc.get(\"id\"))\n",
    "        if all(k):\n",
    "            if md[\"runners\"][0][\"status\"] == 'ACTIVE' and len(md[\"runners\"]) ==2 and md[\"runners\"][0][\"name\"] not in (\"No\", \"Yes\"):\n",
    "                runners = (md[\"runners\"])\n",
    "                unique[k] = {\"eventName\": md.get(\"eventName\"), \"id\": mc.get(\"id\"), \"eventId\": md.get(\"eventId\"), \"runners\": runners}\n",
    "\n",
    "with open(\"input.csv\",\"w\",newline=\"\",encoding=\"utf-8\") as f:\n",
    "    csv.DictWriter(f,fieldnames=[\"eventName\",\"id\",\"eventId\",\"runners\"]).writeheader(); f.writelines(\n",
    "        \",\".join(map(str,row.values()))+\"\\n\" for row in unique.values()\n",
    "    )\n",
    "\n",
    " # Gets all MATCH_ODDS event and market ids into csv brute force  ^^^\n",
    "\n",
    "\n",
    "files = {Path(p).name: p for p in paths}\n",
    "nlines = lambda p: sum(1 for _ in open(p, \"rb\"))\n",
    "\n",
    "with open(\"input.csv\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline().rstrip(\"\\n\")\n",
    "    h1,h2,h3,_ = header.split(\",\", 3)  # eventName,id,eventId,runners\n",
    "    lines = [ln.rstrip(\"\\n\") for ln in f]\n",
    "\n",
    "bad = set()\n",
    "for ln in lines:\n",
    "    try:\n",
    "        _, idv, _, _ = ln.split(\",\", 3)\n",
    "        fp = files.get(idv)\n",
    "        if fp and nlines(fp) < 200:\n",
    "            bad.add(idv)\n",
    "    except ValueError:\n",
    "        continue  # skip malformed rows\n",
    "\n",
    "with open(\"bought_data_catalogue.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(header + \"\\n\")\n",
    "    for ln in lines:\n",
    "        try:\n",
    "            _, idv, _, _ = ln.split(\",\", 3)\n",
    "            if idv not in bad:\n",
    "                f.write(ln + \"\\n\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    " # Cleans up to only have market ids with >200 lines (aka more likely the actual match odds) - wouldnt work on more granual tick data files)\n",
    "\n",
    "with open(\"bought_data_catalogue.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    rows = list(reader)\n",
    "with open(\"bought_data_catalogue.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for count, row in enumerate(rows):\n",
    "        if count >0:\n",
    "            row.append([x for x in files.values() if row[1] in x][0])\n",
    "            writer.writerow(row)\n",
    "        else:\n",
    "            row.append(\"path\")\n",
    "            writer.writerow(row)\n",
    "\n",
    "!rm input.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287c201-8a83-4568-92fe-fbe8a9873a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd9c72-7338-476a-b718-5c50568cc065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Betting Env",
   "language": "python",
   "name": "betting_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
